# Docker Compose configuration for SaaS Multi-Tenant Platform
# This file defines all services needed to run the complete stack locally

services:
  # PostgreSQL Database - Main database for users, tenants, associations
  # Also serves as base for dynamically created tenant databases
  postgres:
    image: postgres:14-alpine
    container_name: saas-postgres
    restart: unless-stopped
    ports:
      - "5432:5432"
    environment:
      POSTGRES_DB: saas_platform
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_INITDB_ARGS: "--encoding=UTF8 --locale=en_US.UTF-8"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./docker/init-scripts:/docker-entrypoint-initdb.d  # Optional init scripts
    networks:
      - saas-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Zookeeper - Required for Kafka coordination
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: saas-zookeeper
    restart: unless-stopped
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
      - zookeeper_logs:/var/lib/zookeeper/log
      - /tmp/zookeeper-secrets:/etc/zookeeper/secrets
    networks:
      - saas-network
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "2181"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Kafka - Message broker for async processing
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: saas-kafka
    restart: unless-stopped
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
      - "9093:9093"  # External access
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    volumes:
      - kafka_data:/var/lib/kafka/data
      - /tmp/kafka-secrets:/etc/kafka/secrets
    networks:
      - saas-network
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 10s
      timeout: 10s
      retries: 5

  # MinIO - S3-compatible object storage
  minio:
    image: minio/minio:latest
    container_name: saas-minio
    restart: unless-stopped
    ports:
      - "9000:9000"  # API
      - "9001:9001"  # Console
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    command: server /data --console-address ":9001"
    volumes:
      - minio_data:/data
    networks:
      - saas-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 10s
      timeout: 5s
      retries: 5

  # MinIO Client - Create buckets on startup
  minio-init:
    image: minio/mc:latest
    container_name: saas-minio-init
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: >
      /bin/sh -c "
      /usr/bin/mc alias set myminio http://minio:9000 minioadmin minioadmin;
      /usr/bin/mc mb myminio/saas-documents --ignore-existing;
      /usr/bin/mc policy set private myminio/saas-documents;
      exit 0;
      "
    networks:
      - saas-network

  # HashiCorp Vault - Secrets management (Production mode)
  vault:
    image: hashicorp/vault:1.15
    container_name: saas-vault
    restart: "no"
    ports:
      - "8201:8200"
    environment:
      VAULT_ADDR: "http://0.0.0.0:8200"
      VAULT_API_ADDR: "http://0.0.0.0:8200"
      SKIP_CHOWN: "true"
    cap_add:
      - IPC_LOCK
    networks:
      - saas-network
    healthcheck:
      test: ["CMD", "vault", "status", "-format=json"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 20s
    volumes:
      - ./docker/volumes/vault/config:/vault/config:ro
      - ./docker/volumes/vault/data:/vault/data
      - ./docker/volumes/vault/logs:/vault/logs
      - /tmp/vault-file:/vault/file  # Évite la création de volumes anonymes
    command: sh -c "chown -R vault:vault /vault/data && exec su-exec vault vault server -config=/vault/config"

  # Vault Unseal - Automatically unseals Vault after startup
  vault-unseal:
    image: hashicorp/vault:1.15
    container_name: saas-vault-unseal
    depends_on:
      vault:
        condition: service_started
    environment:
      VAULT_ADDR: "http://vault:8200"
    volumes:
      - ./docker/volumes/vault/scripts:/scripts:ro
      - ./docker/volumes/vault/data:/vault/data
      - /tmp/vault-unseal-file:/vault/file  # Évite la création de volumes anonymes
      - /tmp/vault-unseal-logs:/vault/logs  # Évite la création de volumes anonymes
    command: /scripts/unseal-vault.sh
    networks:
      - saas-network
    restart: "no"

  # Vault Initialization - Auto-injects secrets and generates AppRole credentials
  vault-init:
    image: hashicorp/vault:1.15
    container_name: saas-vault-init
    depends_on:
      vault-unseal:
        condition: service_completed_successfully
    environment:
      VAULT_ADDR: "http://vault:8200"
      VAULT_ENV: "${VAULT_ENV:-docker}"
    volumes:
      - ./docker/volumes/vault/scripts:/scripts:ro
      - ./docker/volumes/vault/init-data:/init-data:ro
      - ./docker/volumes/vault/data:/vault/data
      - .:/output
      - /tmp/vault-init-file:/vault/file  # Évite la création de volumes anonymes
      - /tmp/vault-init-logs:/vault/logs  # Évite la création de volumes anonymes
    command: /scripts/init-vault.sh
    networks:
      - saas-network
    restart: "no"

  # Flask API - Main REST API server
  api:
    build:
      context: .
      dockerfile: docker/Dockerfile.api
    container_name: saas-api
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
      kafka:
        condition: service_healthy
      minio:
        condition: service_healthy
      redis:
        condition: service_healthy
      vault:
        condition: service_healthy
      vault-init:
        condition: service_completed_successfully
    ports:
      - "4999:4999"
    environment:
      # Flask
      FLASK_ENV: development
      FLASK_APP: run.py
      FLASK_DEBUG: "1"

      # Vault Configuration
      USE_VAULT: "true"
      VAULT_ENVIRONMENT: "docker"

      # Database (fallback values if Vault is disabled)
      DATABASE_URL: postgresql://postgres:postgres@postgres:5432/saas_platform
      TENANT_DATABASE_URL_TEMPLATE: postgresql://postgres:postgres@postgres:5432/{database_name}
      DATABASE_POOL_SIZE: 10
      DATABASE_MAX_OVERFLOW: 20

      # JWT (fallback values if Vault is disabled)
      JWT_SECRET_KEY: dev-secret-key-change-in-production
      JWT_ACCESS_TOKEN_EXPIRES: 900
      JWT_REFRESH_TOKEN_EXPIRES: 604800

      # Kafka
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      KAFKA_CONSUMER_GROUP_ID: saas-consumer-group
      KAFKA_AUTO_OFFSET_RESET: earliest

      # S3 (MinIO) (fallback values if Vault is disabled)
      S3_ENDPOINT_URL: http://minio:9000
      S3_PUBLIC_URL: http://localhost:9000
      S3_ACCESS_KEY_ID: minioadmin
      S3_SECRET_ACCESS_KEY: minioadmin
      S3_BUCKET: saas-documents
      S3_REGION: us-east-1
      S3_USE_SSL: "false"

      # Redis
      REDIS_URL: redis://redis:6379/0
      REDIS_MAX_CONNECTIONS: 20
      REDIS_DECODE_RESPONSES: "true"

      # Celery configuration
      CELERY_BROKER_URL: redis://redis:6379/3
      CELERY_RESULT_BACKEND: redis://redis:6379/4

      # CORS
      CORS_ORIGINS: http://localhost:3000,http://localhost:4999

      # Logging
      LOG_LEVEL: DEBUG
    volumes:
      - ./backend:/app  # Hot reload for development
      - ./logs:/app/logs
      - ./.env.vault:/.env.vault:ro  # Vault credentials (read-only)
    networks:
      - saas-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4999/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Kafka Consumer Worker - Processes async messages
  worker:
    build:
      context: .
      dockerfile: docker/Dockerfile.worker
    container_name: saas-worker
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
      kafka:
        condition: service_healthy
      minio:
        condition: service_healthy
      redis:
        condition: service_healthy
      vault:
        condition: service_healthy
      vault-init:
        condition: service_completed_successfully
    environment:
      # Vault Configuration
      USE_VAULT: "true"
      VAULT_ENVIRONMENT: "docker"

      # Database (fallback values if Vault is disabled)
      DATABASE_URL: postgresql://postgres:postgres@postgres:5432/saas_platform
      TENANT_DATABASE_URL_TEMPLATE: postgresql://postgres:postgres@postgres:5432/{database_name}

      # Kafka
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      KAFKA_CONSUMER_GROUP_ID: saas-consumer-group
      KAFKA_AUTO_OFFSET_RESET: earliest
      KAFKA_ENABLE_AUTO_COMMIT: "true"
      KAFKA_MAX_POLL_RECORDS: 100

      # S3 (MinIO) (fallback values if Vault is disabled)
      S3_ENDPOINT_URL: http://minio:9000
      S3_PUBLIC_URL: http://localhost:9000
      S3_ACCESS_KEY_ID: minioadmin
      S3_SECRET_ACCESS_KEY: minioadmin
      S3_BUCKET: saas-documents
      S3_REGION: us-east-1
      S3_USE_SSL: "false"

      # Redis
      REDIS_URL: redis://redis:6379/0
      REDIS_MAX_CONNECTIONS: 20
      REDIS_DECODE_RESPONSES: "true"

      # Logging
      LOG_LEVEL: DEBUG
    volumes:
      - ./backend:/app  # Hot reload for development
      - ./logs:/app/logs
      - ./.env.vault:/.env.vault:ro  # Vault credentials (read-only)
    networks:
      - saas-network
    healthcheck:
      test: ["CMD", "pgrep", "-f", "python -m app.worker.consumer"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # Redis - For caching, session storage, token blacklist and Celery broker
  redis:
    image: redis:7-alpine
    container_name: saas-redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - saas-network
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru --databases 16
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Celery Worker for SSO tasks
  celery-worker-sso:
    build:
      context: .
      dockerfile: docker/Dockerfile.api
    container_name: saas-celery-worker-sso
    restart: unless-stopped
    command: celery -A celery_worker:celery worker --loglevel=info -Q sso,maintenance -n worker-sso@%h
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      vault:
        condition: service_healthy
      vault-init:
        condition: service_completed_successfully
    environment:
      # Flask/Celery
      FLASK_ENV: development
      FLASK_APP: run.py

      # Celery configuration
      CELERY_BROKER_URL: redis://redis:6379/3
      CELERY_RESULT_BACKEND: redis://redis:6379/4

      # Vault Configuration
      USE_VAULT: "true"
      VAULT_ENVIRONMENT: "docker"

      # Database
      DATABASE_URL: postgresql://postgres:postgres@postgres:5432/saas_platform
      TENANT_DATABASE_URL_TEMPLATE: postgresql://postgres:postgres@postgres:5432/{database_name}

      # Redis for SSO sessions
      REDIS_URL: redis://redis:6379/0
      REDIS_SSO_URL: redis://redis:6379/2

      # Logging
      LOG_LEVEL: INFO
    volumes:
      - ./backend:/app
      - ./logs:/app/logs
      - ./.env.vault:/.env.vault:ro
    networks:
      - saas-network
    healthcheck:
      test: ["CMD", "celery", "-A", "celery_worker:celery", "inspect", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Celery Beat scheduler
  celery-beat:
    build:
      context: .
      dockerfile: docker/Dockerfile.api
    container_name: saas-celery-beat
    restart: unless-stopped
    command: celery -A celery_worker:celery beat --loglevel=info --pidfile=/tmp/celerybeat.pid
    depends_on:
      redis:
        condition: service_healthy
      celery-worker-sso:
        condition: service_started
      vault:
        condition: service_healthy
      vault-init:
        condition: service_completed_successfully
    environment:
      # Flask/Celery
      FLASK_ENV: development
      FLASK_APP: run.py

      # Celery configuration
      CELERY_BROKER_URL: redis://redis:6379/3
      CELERY_RESULT_BACKEND: redis://redis:6379/4

      # Vault Configuration
      USE_VAULT: "true"
      VAULT_ENVIRONMENT: "docker"

      # Database (for task scheduling)
      DATABASE_URL: postgresql://postgres:postgres@postgres:5432/saas_platform

      # Redis
      REDIS_URL: redis://redis:6379/0

      # Logging
      LOG_LEVEL: INFO
    volumes:
      - ./backend:/app
      - celery_beat_schedule:/var/lib/celery
      - ./.env.vault:/.env.vault:ro
    networks:
      - saas-network

  # Flower - Celery monitoring dashboard (optional)
  flower:
    build:
      context: .
      dockerfile: docker/Dockerfile.api
    container_name: saas-celery-flower
    restart: unless-stopped
    command: celery -A app.celery_app:celery_app flower --port=5555 --broker_api=redis://redis:6379/3
    ports:
      - "5555:5555"
    depends_on:
      redis:
        condition: service_healthy
      celery-worker-sso:
        condition: service_started
    environment:
      # Celery configuration
      CELERY_BROKER_URL: redis://redis:6379/3
      CELERY_RESULT_BACKEND: redis://redis:6379/4

      # Flower configuration
      FLOWER_UNAUTHENTICATED_API: "true"  # For development only
      FLOWER_BASIC_AUTH: "admin:admin"  # Change in production
    networks:
      - saas-network

# Named volumes for data persistence
volumes:
  postgres_data:
    driver: local
  minio_data:
    driver: local
  kafka_data:
    driver: local
  zookeeper_data:
    driver: local
  zookeeper_logs:
    driver: local
  # vault_data: Supprimé - utilisation de bind mount local ./vault/data
  redis_data:
    driver: local
  celery_beat_schedule:
    driver: local

# Custom network for service communication
networks:
  saas-network:
    driver: bridge
